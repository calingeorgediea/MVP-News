{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Politică data to category_outputs/Politică.csv\n",
      "No data found for nan, skipping...\n",
      "Saved Actualitate data to category_outputs/Actualitate.csv\n",
      "Saved SUA data to category_outputs/SUA.csv\n",
      "Saved Economie data to category_outputs/Economie.csv\n",
      "Saved Educație data to category_outputs/Educație.csv\n",
      "Saved Justiție data to category_outputs/Justiție.csv\n",
      "Saved Știri data to category_outputs/Știri.csv\n",
      "Saved Sănătate data to category_outputs/Sănătate.csv\n",
      "Saved Externe data to category_outputs/Externe.csv\n",
      "Saved Evenimente data to category_outputs/Evenimente.csv\n",
      "Saved Social data to category_outputs/Social.csv\n",
      "Saved Rusia data to category_outputs/Rusia.csv\n",
      "Saved Bacalaureat 2023 data to category_outputs/Bacalaureat 2023.csv\n",
      "Saved Meteo data to category_outputs/Meteo.csv\n",
      "Saved Sci-tech data to category_outputs/Sci-tech.csv\n",
      "Saved Pacient în România data to category_outputs/Pacient în România.csv\n",
      "Saved Animale data to category_outputs/Animale.csv\n",
      "Saved Evaluare Națională 2023 data to category_outputs/Evaluare Națională 2023.csv\n",
      "Saved Energie data to category_outputs/Energie.csv\n",
      "Saved Digi Economic data to category_outputs/Digi Economic.csv\n",
      "Saved Mapamond data to category_outputs/Mapamond.csv\n",
      "Saved Film data to category_outputs/Film.csv\n",
      "Saved Descoperiri data to category_outputs/Descoperiri.csv\n",
      "Saved Tenis data to category_outputs/Tenis.csv\n",
      "Saved Transporturi data to category_outputs/Transporturi.csv\n",
      "Saved Statul la stat data to category_outputs/Statul la stat.csv\n",
      "Saved Europa data to category_outputs/Europa.csv\n",
      "Saved Natură și Mediu data to category_outputs/Natură și Mediu.csv\n",
      "Saved Opinie și promovare politică data to category_outputs/Opinie și promovare politică.csv\n",
      "Saved Vacanțe data to category_outputs/Vacanțe.csv\n",
      "Saved Lumea digitală data to category_outputs/Lumea digitală.csv\n",
      "Saved Finanțe data to category_outputs/Finanțe.csv\n",
      "Saved Stil de viață data to category_outputs/Stil de viață.csv\n",
      "Saved Interviurile Digi24.ro data to category_outputs/Interviurile Digi24.ro.csv\n",
      "Saved Fara categorie data to category_outputs/Fara categorie.csv\n",
      "Saved Sport data to category_outputs/Sport.csv\n",
      "Saved Showbiz data to category_outputs/Showbiz.csv\n",
      "Saved Agricultură data to category_outputs/Agricultură.csv\n",
      "Saved Companii data to category_outputs/Companii.csv\n",
      "Saved Magazin data to category_outputs/Magazin.csv\n",
      "Saved Fotbal data to category_outputs/Fotbal.csv\n",
      "Saved Divertisment data to category_outputs/Divertisment.csv\n",
      "Saved Auto data to category_outputs/Auto.csv\n",
      "Saved Consumatori data to category_outputs/Consumatori.csv\n",
      "Saved Digi English data to category_outputs/Digi English.csv\n",
      "Saved Timp liber data to category_outputs/Timp liber.csv\n",
      "Saved Cultură data to category_outputs/Cultură.csv\n",
      "Saved Întrebarea săptămânii data to category_outputs/Întrebarea săptămânii.csv\n",
      "Saved Moldova data to category_outputs/Moldova.csv\n",
      "Saved Avem același sânge data to category_outputs/Avem același sânge.csv\n",
      "Saved Opinii data to category_outputs/Opinii.csv\n",
      "Saved Viață sănătoasă data to category_outputs/Viață sănătoasă.csv\n",
      "Saved Agora Digi data to category_outputs/Agora Digi.csv\n",
      "Saved Arte data to category_outputs/Arte.csv\n",
      "Saved Gadget data to category_outputs/Gadget.csv\n",
      "Saved Bani și Afaceri data to category_outputs/Bani și Afaceri.csv\n",
      "Saved Diverse data to category_outputs/Diverse.csv\n",
      "Saved Familie data to category_outputs/Familie.csv\n"
     ]
    }
   ],
   "source": [
    "## save to different categories\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Read the main CSV file\n",
    "df = pd.read_csv(\"cool.csv\")\n",
    "\n",
    "# Define the columns to keep in the output\n",
    "columns_to_keep = [\n",
    "    '_id', 'category', 'content',\n",
    "    'cleaned_tokens_ner', 'cleaned_tokens_stopwords', 'tokens'\n",
    "]\n",
    "\n",
    "# Get unique categories\n",
    "categories = df['category'].unique()\n",
    "\n",
    "# Create a directory for outputs\n",
    "output_dir = \"category_outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate over categories\n",
    "for category in categories:\n",
    "    # Filter data for the current category\n",
    "    category_df = df[df['category'] == category]\n",
    "    \n",
    "    # Check if there are any rows for this category\n",
    "    if not category_df.empty:\n",
    "        # Prepare the output filename\n",
    "        output_filename = os.path.join(output_dir, f\"{category}.csv\")\n",
    "        \n",
    "        # Save the category data to a new CSV file\n",
    "        category_df[columns_to_keep].to_csv(output_filename, index=False)\n",
    "        print(f\"Saved {category} data to {output_filename}\")\n",
    "    else:\n",
    "        print(f\"No data found for {category}, skipping...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0\n",
      "Words: ['clădire', 'cutremur', 'seismic', 'risc', 'concurenă', 'judeu', 'oră', 'cca', 'cod', 'magnitudine']\n",
      "\n",
      "Topic: 1\n",
      "Words: ['spune', 'an', 'spital', 'caz', 'leu', 'ban', 'românia', 'trebui', 'lua', 'număr']\n",
      "\n",
      "Topic: 2\n",
      "Words: ['aeroport', 'companie', 'astronaut', 'damen', 'esa', 'zbor', 'aeronavă', 'mangalia', 'air', 'chatgpt']\n",
      "\n",
      "Topic: 3\n",
      "Words: ['oră', 'loc', 'număr', 'afla', 'incendiu', 'pompier', 'român', 'isu', 'mesaj', 'apă']\n",
      "\n",
      "Topic: 4\n",
      "Words: ['trebui', 'spune', 'putea', 'leu', 'sistem', 'proiect', 'program', 'public', 'energie', 'guvern']\n",
      "\n",
      "Topic: 5\n",
      "Words: ['an', 'cookie', 'loc', 'social', 'permite', 'editor', 'afla', 'zonă', 'direct', 'accident']\n",
      "\n",
      "Topic: 6\n",
      "Words: ['biserică', 'sfânt', 'ortodox', 'lumină', 'bisericii', 'înviere', 'slujbă', 'calendar', 'domn', 'mormânt']\n",
      "\n",
      "Topic: 7\n",
      "Words: ['grad', 'lege', 'zonă', 'parte', 'român', 'perioadă', 'minister', 'spune', 'lucrare', 'exista']\n",
      "\n",
      "Topic: 8\n",
      "Words: ['românia', 'ucraina', 'european', 'stat', 'spune', 'rusia', 'rus', 'război', 'român', 'ucrainean']\n",
      "\n",
      "Topic: 9\n",
      "Words: ['kilometru', 'cadru', 'zonă', 'trafic', 'bucureti', 'serviciu', 'persoană', 'drog', 'urma', 'efectua']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from spacy.lang.ro.stop_words import STOP_WORDS\n",
    "import pandas as pd\n",
    "\n",
    "def text_pipeline(data_file, num_topics=10, passes=15):\n",
    "    # Load the spaCy model for Romanian\n",
    "    nlp = spacy.load(\"ro_core_news_sm\")\n",
    "\n",
    "    # Load your text data from CSV\n",
    "    texts = pd.read_csv(data_file)\n",
    "\n",
    "    # Tokenize, remove stopwords, and get document vectors\n",
    "    def process_text(text):\n",
    "        doc = nlp(text)\n",
    "        processed_text = [token.text.lower() for token in doc if token.text.lower() not in STOP_WORDS and token.is_alpha]\n",
    "        return processed_text\n",
    "\n",
    "    processed_texts = [process_text(text) for text in texts['tokens']]\n",
    "\n",
    "    # Create a dictionary representation of the documents\n",
    "    dictionary = corpora.Dictionary(processed_texts)\n",
    "\n",
    "    # Create corpus of document vectors\n",
    "    corpus = [dictionary.doc2bow(text) for text in processed_texts]\n",
    "\n",
    "    # Train the LDA model\n",
    "    lda_model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=passes)\n",
    "\n",
    "    # Print the topics and their corresponding words without weights\n",
    "    for idx, topic in lda_model.print_topics(10):\n",
    "        words = topic.split('+')\n",
    "        topic_words = [word.split('*')[1].replace('\"', '').strip() for word in words]\n",
    "        print(f'Topic: {idx}')\n",
    "        print(f'Words: {topic_words}')\n",
    "        print()\n",
    "\n",
    "    # Save the LDA model\n",
    "    lda_model.save('lda_model_spacy')\n",
    "\n",
    "# Example Usage:\n",
    "text_pipeline('Actualitate.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
