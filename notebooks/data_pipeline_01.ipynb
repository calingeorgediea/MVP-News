{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LDA for category: Politică\n",
      "Optimal number of topics: 2\n",
      "Topic 0: 'profesor',, 'spune',, 'sindicat',, 'transmite',, 'palat',, 'declara',, 'grevă',, 'preşedinte',, 'ministru',, 'România',\n",
      "Topic 1: 'ministru',, 'sindicat',, 'profesor',, 'grevă',, 'România',, 'palat',, 'preşedinte',, 'declara',, 'transmite',, 'spune',\n",
      "Training LDA for category: nan\n",
      "No documents for category: nan. Skipping...\n",
      "Training LDA for category: Actualitate\n",
      "Optimal number of topics: 2\n",
      "Topic 0: 'România',, 'dată',, 'naţional',, 'zi',, 'iunie',, 'preciza',, 'cita',, 'putea',, 'urma',\n",
      "Topic 1: 'urma',, 'putea',, 'iunie',, 'cita',, 'preciza',, 'zi',, 'naţional',, 'dată',, 'România',\n",
      "Training LDA for category: SUA\n",
      "Error: cannot compute LDA over an empty collection (no terms). Skipping...\n",
      "Training LDA for category: Economie\n",
      "Error: cannot compute LDA over an empty collection (no terms). Skipping...\n",
      "Training LDA for category: Educație\n",
      "Error: cannot compute LDA over an empty collection (no terms). Skipping...\n",
      "Training LDA for category: Justiție\n",
      "Error: cannot compute LDA over an empty collection (no terms). Skipping...\n",
      "Training LDA for category: Știri\n",
      "Error: cannot compute LDA over an empty collection (no terms). Skipping...\n",
      "Training LDA for category: Sănătate\n",
      "Error: cannot compute LDA over an empty collection (no terms). Skipping...\n",
      "Training LDA for category: Externe\n",
      "Error: cannot compute LDA over an empty collection (no terms). Skipping...\n",
      "Training LDA for category: Evenimente\n",
      "Error: cannot compute LDA over an empty collection (no terms). Skipping...\n",
      "Training LDA for category: Social\n",
      "Error: cannot compute LDA over an empty collection (no terms). Skipping...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Load the CSV file with tokenized content\n",
    "df = pd.read_csv(\"tokenized_output.csv\")\n",
    "\n",
    "# Assuming you have a column \"category\" in your CSV that indicates the category of each headline\n",
    "categories = df[\"category\"].unique()\n",
    "\n",
    "for category in categories:\n",
    "    print(f\"Training LDA for category: {category}\")\n",
    "    \n",
    "    # Filter the dataframe for the current category\n",
    "    category_df = df[df[\"category\"] == category]\n",
    "    \n",
    "    # Create a list of tokenized documents for this category\n",
    "    tokenized_docs = [doc.split() for doc in category_df[\"tokens\"].values]\n",
    "    \n",
    "    # Check if there are no tokenized documents for this category\n",
    "    if not tokenized_docs:\n",
    "        print(f\"No documents for category: {category}. Skipping...\")\n",
    "        continue\n",
    "    \n",
    "    # Create a dictionary representation of the documents\n",
    "    dictionary = corpora.Dictionary(tokenized_docs)\n",
    "    \n",
    "    # Filter out tokens that appear in less than 5 documents or more than 50% of the documents\n",
    "    dictionary.filter_extremes(no_below=5, no_above=0.5)\n",
    "    \n",
    "    # Create a bag-of-words representation of the documents\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in tokenized_docs]\n",
    "    \n",
    "    # Function to compute coherence score for a given number of topics\n",
    "    def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=1):\n",
    "        coherence_values = []\n",
    "        model_list = []\n",
    "        \n",
    "        for num_topics in range(start, limit, step):\n",
    "            model = LdaMulticore(corpus=corpus,\n",
    "                                 id2word=dictionary,\n",
    "                                 num_topics=num_topics,\n",
    "                                 workers=3,  # Adjust based on your system\n",
    "                                 passes=100)  # Number of passes through the corpus\n",
    "            model_list.append(model)\n",
    "            coherence_model = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "            coherence_values.append(coherence_model.get_coherence())\n",
    "        \n",
    "        return model_list, coherence_values\n",
    "    \n",
    "    # Set the range of topics to try\n",
    "    start_topics = 2\n",
    "    limit_topics = 20\n",
    "    step_topics = 1\n",
    "    \n",
    "    try:\n",
    "        # Compute coherence values for different number of topics\n",
    "        model_list, coherence_values = compute_coherence_values(dictionary=dictionary, corpus=corpus, texts=tokenized_docs,\n",
    "                                                                start=start_topics, limit=limit_topics, step=step_topics)\n",
    "        \n",
    "        # Find the optimal number of topics with the highest coherence value\n",
    "        optimal_num_topics = start_topics + coherence_values.index(max(coherence_values))\n",
    "        print(\"Optimal number of topics:\", optimal_num_topics)\n",
    "        \n",
    "        # Build the LDA model with the optimal number of topics\n",
    "        lda_model = model_list[coherence_values.index(max(coherence_values))]\n",
    "        \n",
    "        # Print the top terms for each topic\n",
    "        for idx, topic in lda_model.print_topics(-1):\n",
    "            terms = topic.split(\"+\")\n",
    "            terms = [term.split(\"*\")[1].strip().replace('\"', '') for term in terms][:10]\n",
    "            print(\"Topic {}: {}\".format(idx, \", \".join(terms)))\n",
    "        \n",
    "        # Save the model if needed for each category\n",
    "        # lda_model.save(f\"lda_model_{category}.model\")\n",
    "    \n",
    "    except ValueError as e:\n",
    "        print(f\"Error: {e}. Skipping...\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
